{
    "collab_server" : "",
    "contents" : "library(tidyverse)\nlibrary(stringr)\n\ninstall.packages(\"dplyr\", dependencies = TRUE)\n\nguns <- read_csv('gun_sale_database-openrefined.csv')\n\n#First, I used Tabula to create a CSV from a PDF. Then, in an effort to reduce duplicates when joining the tables, which don't have this unique ID number that is included in the PDF....I'll ask about that when I hear from the State Police. In the meantime, I did a slight modification to this sheet. I removed one of the Atlantic Guns locations. They are both in Montgomery county, but were getting doubled, I also removed a duplicate in spelling J & S pawn had two separate spellings of the same address. And I changed the name of 1237 gun shop to .1237 to be consisitent with the guns table it is saved into a new spreadsheet. \nshops <- read_csv('mod_active_firearms_dealers_new.csv')\n\n\n#this database also may contain non-gun parts like magazines and other gun accessories. May need to split data into two sets one that has null items under barrel length one that does not have nulls in barrel length. \n#I also found through some testing that there are duplicate values in application numbers....I first detected this when I did a left join and got more observations then when I started. That will have to be dealt witjh at a later date.  I don't know why this is and will ask the state police upon getting a new version of this data. However, for the time being, I will use the distinct() operator in DPLYR to see if I can try and cut out these duplicates. \n\n#NOTICED THAT there are multiple values in the guns table. \nguns_count <- guns %>%\n  group_by (`Application Number`, `Dealer Name` )%>%\n  summarise(count = n()) %>%\n   arrange(desc(count))\n\n#went back and made sure the appliocation numbers and observation values are the same before and after data cleaning. The code is noted out so it doesn't run unless needed, but saved for posterity.  \n#guns <- read_csv('gun_sale_database-openrefined.csv', col_names = T)\n#guns2 <- read_csv('gun_sale_database.csv')\n\n#for both below, I found that there are 77 observations for this application number in both datasets.  \n#guns_filter <- guns %>%\n#  filter(`Application Number` == '2017014401')\n\n#guns2_filter <- guns2 %>%\n#  filter(`Application Number` == '2017014401')\n\n#So first I thought I was getting duplicates, so I decided to select all discinct records.\n#distinct_guns <- distinct(guns, `Application Number`, .keep_all = TRUE)\n#but after talking to the MD. State Police, I was told by Capt. Barrett that the guns were likely from orders with multiple guns. \n\n  \n#ok. So now I know I can leave in the duplicates. So I'll join the guns with the shops on dealer name. \n\nguns_and_shops <-  left_join(guns, shops, by = \"Dealer Name\")\n\n# Alright, with all that annoying data cleaning and joining out of the way, I can start looking at stuff, like where guns are sold in the state and how many. \n\nnames(guns)\n\n\n#let's look at the gun models \ngun_models <- guns_and_shops %>%\n  #the colum we are grouping \n  group_by(Model )  %>%\n  #creates a count with the row name being count. The n value is the number of times it occurs\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(gun_models)\ngun_models[1:10,]\n\n#Remington just declared bankriuptsy. Let's see which brand was most popular.  Wow, there's a few duplicate names for Remington, but dang, they only sold like 300 guns...But don't forget. This is just handguns mostly. \n\n#what makes are being sold? \ngun_make <- guns_and_shops %>%\n  group_by(Make ) %>%\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(gun_make)\ngun_make[1:10,]\n\n\n#where are these guns being sold?   This is a problem, because the state gave a .pdf qwithout all the gun shop names. We need to go back and make sure all the names are there. There is a code in the gun database, but not the shop database. Will follow up with the state. \ngun_sales <- guns_and_shops %>%\n  group_by(`Dealer Name`, County ) %>%\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(gun_sales)\ngun_sales[1:10,]\n\n#There's a couple dealers that have a few locations. Let's just sort it by dealer name.....not much changed. \ngun_shop_sales <- guns_and_shops %>%\n  group_by(`Dealer Name`) %>%\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(gun_shop_sales)\ngun_shop_sales[1:10,]\n\n#This groups the counties where these gun shops are from. Hopefully new informaiton will enrich this query, whihch counts the number of sales per county. \n\ngun_shop_county <- guns_and_shops %>%\n  group_by(County ) %>%\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(gun_shop_county)\ngun_shop_county[1:10,]\n\n#what caliber weapons are being sold?\ngun_caliber <- guns_and_shops %>%\n  group_by( Caliber) %>%\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(gun_caliber)\ngun_caliber[1:10,]\n\n\n\n#modeled from https://awakeningdatascientist.wordpress.com/2015/07/20/r-of-the-day-grep-and-grepl/ \n#Here I'm searching for guns that take big (ish) bullets. I'm trying to find weapons that have calibners that are used in assault-style weapons. I used the List of AR platform calibers page (https://en.wikipedia.org/wiki/List_of_AR_platform_calibers) from Wikipedia to build my list. I added both decimal and-non-decimal versions to make sure I was getting all the possible entries. \n\nbig_bullets <- guns_and_shops %>%\n  filter(grepl(\"5.45|545|5.56|556|5.7|6.5|65|6.8|68|7.62|762|223|.223\", Caliber)) %>%\n  group_by(Model) %>%\n  summarise(count = n()) %>%\n  arrange(desc(count))\n  View(big_bullets)\n  \n  \n  \n  \n  \n#Now I'm looking for 9mm guns, so I use a grepl filter to grab all the values htat have a 9 in them. And just to makje sure I'm not grabbing any other calibers, I tlel the computer, hey, ignore all the calibers that could fit in the 'assault-style' category.   And Then, just count it up. \n  \n ninemm_guns <- guns_and_shops %>%\n    filter(grepl(\"9\", Caliber, ignore.case = T)) %>%\n   filter(!grepl(\"5.45|545|5.56|556|5.7|6.5|65|6.8|68|7.62|762\", Caliber)) %>%\n    summarise(count = n()) %>%\n    arrange(desc(count))\n  View( ninemm_guns)\n  \n#If i Just want to see what individual giuns were most popular I'll add back in caliber and model. That way I can check my work. \n  \n  \n  ninemm_guns <- guns_and_shops %>%\n    filter(grepl(\"9\", Caliber, ignore.case = T)) %>%\n    filter(!grepl(\"5.45|545|5.56|556|5.7|6.5|65|6.8|68|7.62|762\", Caliber)) %>%\n    group_by(Caliber, Model) %>%\n    summarise(count = n()) %>%\n    arrange(desc(count))\n  View( ninemm_guns)\n  \n  \n  \n  \n#looking for a different way to evaluate caliber, I dwecided to see if there was a differnet method. This technique just uses the str_extract function to pull out all nunbers, and drop all letters. \n  \n# Found this from http://stla.github.io/stlapblog/posts/Numextract.html. It extracts numbers from strings. \n\n  \nnumextract <- function(string){ \n   str_extract(string, \"\\\\-*\\\\d+\\\\.*\\\\d*\")\n } \n \n \ncaliber_digits <- numextract(guns$Caliber)\n \ncaliber_digits_df <- data.frame(caliber_digits)\nView(caliber_digits_df)\n  \n#now I'm counting it up.....And it looks like It's pretty similar. I'll probably jsut got witht he ones that have characters rto make sure I'm not making  mistakes. \n\ncaliber_digit_counts <- caliber_digits_df %>%\n  #the colum we are grouping \n  group_by(caliber_digits)  %>%\n  #creates a count with the row name being count. The n value is the number of times it occurs\n  summarise(count = n()) %>%\n  #arrange the list in descending order\n  arrange(desc(count)) \nView(caliber_digit_counts)\ncaliber_digit_counts[1:10,]\n  \n\n\nlibrary(lubridate)\ncrime_data <- read_csv(\"violent_crime_maryland.csv\")\n#weird. My sorting's not working. Aha it's because they're not dagte fields\nclass(crime_data$YEAR)\n#ok lert's make it a date field. \ncrime_Date_new <- data.frame(as.Date(crime_data$YEAR, \"%m/%d/%Y\")) \n#and then we'll change the name to something reasonable. \nnames(crime_Date_new)[names(crime_Date_new) == 'as.Date.crime_data.YEAR....m..d..Y..'] <- 'cleaned_date'\n\n#OK. Now let's join them together, so we can sort better. Hoperfully this works. Because otherwise my life was for naught. \ncrime_data_years <- cbind(crime_data, crime_Date_new)\n\n#and now let's pull data dated 2015 or later, the latest year there is.....I assume there's an easier way to do that, but I don't care. \nLatest_year <- crime_data_years %>%\n  filter(cleaned_date >= as.Date(\"2015-01-01\"))\n\n",
    "created" : 1521302742930.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "193234367",
    "id" : "D7AD3303",
    "lastKnownWriteTime" : 1522698309,
    "last_content_update" : 1522698309420,
    "path" : "~/Documents/GitHub/gun_examination/gun_examination_code.R",
    "project_path" : "gun_examination_code.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}